{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5946fb-a333-4eae-9754-b83978f93b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_frames_from_folder(subject_folder_path):\n",
    "    \"\"\"\n",
    "    Extract frames from all .avi video clips in the specified folder and save them in a 'Separated_Frames' subfolder.\n",
    "    \n",
    "    Parameters:\n",
    "    - subject_folder_path: Path to the folder containing .avi video clips.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the subject folder exists\n",
    "    if not os.path.exists(subject_folder_path):\n",
    "        print(f\"Error: The folder '{subject_folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # List all .avi files in the subject folder\n",
    "    avi_files = [f for f in os.listdir(subject_folder_path) if f.endswith('.avi')]\n",
    "    all_frames = 0\n",
    "    # Inform the user about the total number of clips in the folder\n",
    "    print(f\"\\t...total clips in the folder: {len(avi_files)}\")\n",
    "\n",
    "    # Check if there are any .avi files in the folder\n",
    "    if not avi_files:\n",
    "        print(f\"No .avi files found in the folder '{subject_folder_path}'.\")\n",
    "        return\n",
    "\n",
    "    # Create the 'Separated_Frames' subfolder inside the subject folder\n",
    "    output_folder = os.path.join(subject_folder_path, 'Separated_Frames')\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"\\t...creating a new folder to store frames from clips at: {output_folder}\")\n",
    "\n",
    "    for n, avi_file in enumerate(avi_files):\n",
    "        video_path = os.path.join(subject_folder_path, avi_file)\n",
    "        \n",
    "        # Check if the video file exists (just to be extra cautious)\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Error: The video file '{video_path}' does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        # Create a sub-folder for the extracted frames of this video inside the 'Separated_Frames' folder\n",
    "        video_name = os.path.splitext(avi_file)[0]  # Remove the .avi extension\n",
    "        video_output_folder = os.path.join(output_folder, video_name)\n",
    "        \n",
    "        if not os.path.exists(video_output_folder):\n",
    "            os.makedirs(video_output_folder)\n",
    "\n",
    "        # Open the video using OpenCV\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # Check if the video was opened successfully\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Unable to open the video file '{video_path}'.\")\n",
    "            continue\n",
    "\n",
    "        # Get the total number of frames\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Loop through each frame and save it as an image\n",
    "        for frame_num in range(total_frames):\n",
    "            all_frames += 1\n",
    "            print(f\"\\r\\t...extracting frame: {frame_num} from clip: {n} of {len(avi_files)}  \", end='', flush=True)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Unable to read frame {frame_num} from video '{video_path}'.\")\n",
    "                break\n",
    "            # Construct the output image path\n",
    "            output_image_path = os.path.join(video_output_folder, f\"frame_{frame_num:04d}.png\")\n",
    "            cv2.imwrite(output_image_path, frame)\n",
    "\n",
    "        # Release the video capture object\n",
    "        cap.release()\n",
    "\n",
    "    # Print the summary\n",
    "    example_frame_name = os.path.join(video_output_folder, \"frame_0000.png\")\n",
    "    print(f\"\\n\\n   SUMMARY: \\n\\tExtracted {all_frames} frames from the folder '{subject_folder_path}' and saved in '{output_folder}'\")\n",
    "    print(f\"\\tTotal clips extracted: {len(avi_files)}\")\n",
    "    print(f\"\\tExample frame name: {example_frame_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5548d1-cb3a-48d6-a762-f4bf9b016b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data_from_frames_VGG16(base_folder, emotion_to_int, emotion_labels):\n",
    "    \"\"\"\n",
    "    Prepare data from frames using the VGG16 pre-trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\t...loading VGG16 pre-trained model', flush=True)\n",
    "    # Load VGG16 model without the top classification layers\n",
    "    base_model = VGG16(weights='imagenet', include_top=False)\n",
    "    feature_extractor = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
    "\n",
    "    frames_folder = os.path.join(base_folder, 'Separated_Frames')\n",
    "    emotion_folders = sorted(os.listdir(frames_folder))\n",
    "    \n",
    "    print(f\"\\t...found {len(emotion_folders)} folders of frames, each from a clip\", flush=True)\n",
    "    \n",
    "    print('\\t\\t...resizing frames...', flush=True)\n",
    "    print('\\t\\t...extracting features with the CNN model...', flush=True)\n",
    "    print('\\t\\t...creating labels from titles of folders...', flush=True)\n",
    "    \n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    total_folders = len(emotion_folders)\n",
    "    \n",
    "    for idx, emotion_folder in enumerate(emotion_folders, 1):\n",
    "\n",
    "        emotion_folder_path = os.path.join(frames_folder, emotion_folder)\n",
    "        if not os.path.isdir(emotion_folder_path):\n",
    "            continue\n",
    "\n",
    "        clip_files = sorted(os.listdir(emotion_folder_path))\n",
    "        total_files = len(clip_files)\n",
    "        clip_features = []\n",
    "        \n",
    "        for file_idx, clip_file in enumerate(clip_files):\n",
    "            print(f\"\\r\\t\\t...of file {file_idx+1:03}/{total_files} in folder {idx}, called {emotion_folder}  \", end='', flush=True)\n",
    "            \n",
    "            clip_path = os.path.join(emotion_folder_path, clip_file)\n",
    "            frame = cv2.imread(clip_path)\n",
    "            \n",
    "            if frame is None:\n",
    "                print(f\"\\tError reading image: {clip_path}\")\n",
    "                continue\n",
    "\n",
    "            # Resize the frame to 224x224 pixels and convert to RGB\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            frame = preprocess_input(frame)  # VGG16 specific preprocessing\n",
    "            frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "            feature_vector = feature_extractor.predict(frame)\n",
    "            flattened_vector = np.reshape(feature_vector, (25088,))  # Flatten the feature_vector\n",
    "            clip_features.append(flattened_vector)  # Append the feature vector without adding an extra dimension\n",
    "\n",
    "        sequences.append(clip_features)\n",
    "        labels.append(emotion_to_int[map_to_emotion(emotion_folder)])\n",
    "\n",
    "    print(f\"\\n\\n   SUMMARY: \\n\\tProcessed all emotion folders from '{frames_folder}'\", flush=True)\n",
    "    print(f\"\\t    Total folders processed: {len(sequences)}\", flush=True)\n",
    "    print(f\"\\t    Labels assigned: {labels}\", flush=True)\n",
    "\n",
    "    return sequences, np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ef5796-0039-447b-970c-2e203aba7ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_jitter(sequence, factor=0.05):\n",
    "    # Add some jitter to the sequence for data augmentation\n",
    "    noise = np.random.normal(0, factor, sequence.shape)\n",
    "    return sequence + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c910daeb-a41a-429e-9527-28f7763e0f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomPrintCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        train_acc = logs.get('accuracy')\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        print(f\"\\r\\t\\tEpoch {epoch+1} - train_accuracy: {train_acc:.4f} - val_accuracy: {val_acc:.4f}\", end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e50f6c-c90e-448d-96fe-0cfb9aebe3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_lstm_VGG16(sequences, y_train_labels, emotion_labels):\n",
    "    print('\\t...preprocessing inputs', flush=True)\n",
    "    \n",
    "    print(\"\\t\\t...randomly shuffling sequences and labels'\", flush=True)\n",
    "    # Shuffle the sequences and labels\n",
    "    shuffled_indices = np.arange(len(sequences))\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    sequences = [sequences[i] for i in shuffled_indices]\n",
    "    y_train_labels = y_train_labels[shuffled_indices]\n",
    "\n",
    "    print(\"\\t\\t...padding sequences of features with 'post'\", flush=True)\n",
    "    # Pad sequences to the length of the longest sequence\n",
    "    padded_sequences = pad_sequences(sequences, padding='post', dtype='float32')\n",
    "    \n",
    "\n",
    "    # Convert to numpy array\n",
    "    sequences_array = np.array(padded_sequences)\n",
    "    \n",
    "    print('\\t\\t...transforming labels with one-hot encoding', flush=True)\n",
    "    y_train_onehot = to_categorical(y_train_labels, num_classes=len(emotion_labels))\n",
    "    \n",
    "     # Ask the user if they want to verify the inputs\n",
    "    verify_choice = input(\"\\nWould you like to verify the inputs before proceeding? (yes/no): \").lower()\n",
    "    \n",
    "    if verify_choice == \"yes\":\n",
    "        while True:\n",
    "            print(\"\\n\\tChoose a method of verification:\")\n",
    "            print(\"\\t1. Display a summary of the data (shape, data type).\")\n",
    "            print(\"\\t2. Display the first few rows of the data.\")\n",
    "            print(\"\\t3. Display random samples from the data.\")\n",
    "            print(\"\\t4. Display basic statistics for the data.\")\n",
    "            print(\"\\t5. Proceed without further verification.\")\n",
    "            \n",
    "            verification_method = input(\"Enter your choice (1/2/3/4/5): \")\n",
    "            \n",
    "            if verification_method == \"1\":\n",
    "                print(\"\\n\\t\\tSequences shape:\", sequences_array.shape)\n",
    "                print(\"\\t\\tOne-hot encoded labels shape:\", y_train_onehot.shape)\n",
    "            elif verification_method == \"2\":\n",
    "                print(\"\\n\\t\\tFirst few rows of sequences:\\n\", sequences_array[:5])\n",
    "                print(\"\\n\\t\\tFirst few rows of one-hot encoded labels:\\n\", y_train_onehot[:5])\n",
    "            elif verification_method == \"3\":\n",
    "                random_idx = np.random.randint(0, len(sequences_array), 5)\n",
    "                print(\"\\n\\t\\tRandom samples from sequences:\\n\", sequences_array[random_idx])\n",
    "                print(\"\\n\\t\\tRandom samples from one-hot encoded labels:\\n\", y_train_onehot[random_idx])\n",
    "            elif verification_method == \"4\":\n",
    "                print(\"\\n\\t\\tSequences mean:\", np.mean(sequences_array))\n",
    "                print(\"\\t\\tSequences median:\", np.median(sequences_array))\n",
    "                print(\"\\t\\tSequences standard deviation:\", np.std(sequences_array))\n",
    "            elif verification_method == \"5\":\n",
    "                break\n",
    "            else:\n",
    "                print(\"\\nInvalid choice. Please choose again.\")\n",
    "    \n",
    "    print('\\t...creating the model', flush=True)\n",
    "    # Define the input shape for the feature vectors\n",
    "    input_shape = (None, 25088)  # Variable sequence length and VGG16 feature shape\n",
    "\n",
    "     # Flatten the VGG16 features before feeding them to the LSTM\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = TimeDistributed(Flatten())(inputs)\n",
    "    x = LSTM(128, return_sequences=False)(x)  # Process the sequence with LSTM layers\n",
    "    x = Dropout(0.5)(x)  # Added dropout for regularization\n",
    "    outputs = Dense(len(emotion_labels), activation='softmax')(x)  # Classification layer\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Our_Chosen_RNN_Model_VGG16\")\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    optimizer = Adam(learning_rate=0.0005)  # Adjusted learning rate\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print('\\n')\n",
    "    print('*'*70)\n",
    "    model.summary()\n",
    "    print('Dropout: 0.5', '\\nActivation: SoftMax', '\\nOptimizer: Adam(learning_rate=0.0005)', '\\nLoss: loss: categorical_crossentropy')\n",
    "    print('*'*70, '\\n')\n",
    "    print(\"\\t...implementing data-augmentation with 'jitter'\", end='', flush=True)\n",
    "    # Augment the entire dataset\n",
    "    X_augmented = [add_jitter(seq) for seq in sequences_array]\n",
    "    X_augmented = np.array(X_augmented)\n",
    "    X_augmented = X_augmented.reshape(X_augmented.shape[0], X_augmented.shape[1], -1)\n",
    "    \n",
    "    print('\\n\\t...training the model with k-fold validation', end='', flush=True)\n",
    "    # Define number of splits\n",
    "    n_splits = 5\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    best_val_accuracy = 0  # to keep track of the best validation accuracy\n",
    "    best_model = None  # to store the best model\n",
    "    best_fold = 0\n",
    "    accuracies = []\n",
    "    fold = 1\n",
    "    \n",
    "    custom_print_callback = CustomPrintCallback()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_augmented, y_train_labels):\n",
    "        print(f\"\\n\\t   Training on fold {fold}/{n_splits}\")\n",
    "\n",
    "        # Split data into training and validation sets for the current fold\n",
    "        X_train_fold, X_val_fold = X_augmented[train_index], X_augmented[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_onehot[train_index], y_train_onehot[val_index]\n",
    "\n",
    "        # Train the model\n",
    "        # history = model.fit(X_train_fold, y_train_fold, epochs=100, batch_size=16, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping])\n",
    "        history = model.fit(X_train_fold, y_train_fold, epochs=100, batch_size=16, validation_data=(X_val_fold, y_val_fold), verbose=0,\n",
    "                            callbacks=[custom_print_callback, early_stopping])\n",
    "\n",
    "        # After training, get the validation accuracy for this fold\n",
    "        val_accuracy = history.history['val_accuracy'][-1]  # get the last epoch's validation accuracy\n",
    "        accuracies.append(val_accuracy)\n",
    "\n",
    "        # Check if this model performs better than previous ones\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model  # store the current model as the best model\n",
    "            best_fold = fold\n",
    "        fold += 1\n",
    "        \n",
    "    print(f'\\n\\t...saving the best model from fold: {best_fold} with accuracy: {best_val_accuracy} as: Models/best_rnn_model.h5', flush=True)\n",
    "    # After all folds are done, save the best model\n",
    "    best_model.save(\"Models/best_rnn_model.h5\")\n",
    "    \n",
    "    print(\"\\n\\n4) Evaluation\")\n",
    "    evaluate_model(best_model, history, X_val_fold, y_val_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d06a24-fd50-430f-8006-6d924821ec1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(best_model, X_val_fold, y_val_fold, emotion_labels):\n",
    "    # Get the model's predictions\n",
    "    y_pred_probs = best_model.predict(X_val_fold)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Convert one-hot encoded y_val_fold back to label indices\n",
    "    y_true = np.argmax(y_val_fold, axis=1)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm_data = confusion_matrix(y_true, y_pred, labels=range(len(emotion_labels)))\n",
    "    \n",
    "    # Convert the confusion matrix to a DataFrame for visualization\n",
    "    cm = pd.DataFrame(cm_data, columns=emotion_labels, index=emotion_labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.title('Confusion Matrix', fontsize=20)\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(cm, cbar=False, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt='g')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47c98327-e176-4dfe-8464-d21adbd523a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(best_model, history, X_val_fold, y_val_fold):\n",
    "    \n",
    "    y_pred = best_model.predict(X_val_fold)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_val_fold, axis=1)\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n    Choose an evaluation option:\")\n",
    "        print(\"\\t1) Evaluate on validation set\")\n",
    "        print(\"\\t2) Plot training loss vs validation loss graph\")\n",
    "        print(\"\\t3) Plot training accuracy vs validation accuracy graph\")\n",
    "        print(\"\\t4) Print confusion matrix\")\n",
    "        print(\"\\t5) Print classification report\")\n",
    "        print(\"\\t6) Exit evaluation\")\n",
    "\n",
    "        choice = input(\"\\nEnter your choice (1/2/3/4/5/6): \")\n",
    "\n",
    "        if choice == \"1\":\n",
    "            accuracy = np.mean(y_true == y_pred_classes)\n",
    "            print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "        elif choice == \"2\":\n",
    "            plt.plot(history.history[\"loss\"],'r', label=\"Training Loss\")\n",
    "            plt.plot(history.history[\"val_loss\"],'b', label=\"Validation Loss\")\n",
    "            plt.legend()\n",
    "            plt.show() \n",
    "            # plot_loss(history)\n",
    "        elif choice == \"3\":\n",
    "            plt.plot(history.history[\"accuracy\"],'r',label=\"Training Accuracy\")\n",
    "            plt.plot(history.history[\"val_accuracy\"],'b',label=\"Validation Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.show() \n",
    "            # plot_accuracy(history)\n",
    "        elif choice == \"4\":\n",
    "             plot_confusion_matrix(best_model, X_val_fold, y_val_fold, emotion_labels)\n",
    "        elif choice == \"5\":\n",
    "            print(\"Classification Report:\")\n",
    "            print(classification_report(y_true, y_pred_classes))\n",
    "        elif choice == \"6\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter a number between 1 and 5.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
